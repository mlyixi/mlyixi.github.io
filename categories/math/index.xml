<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>math on mlyixi的博客</title><link>https://mlyixi.github.io/categories/math/</link><description>Recent content in math on mlyixi的博客</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Thu, 29 Jan 2015 15:08:52 +0800</lastBuildDate><atom:link href="https://mlyixi.github.io/categories/math/index.xml" rel="self" type="application/rss+xml"/><item><title>数理统计学6-一个样本的统计推断</title><link>https://mlyixi.github.io/post/math/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%AD%A66-%E4%B8%80%E4%B8%AA%E6%A0%B7%E6%9C%AC%E7%9A%84%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD/</link><pubDate>Thu, 29 Jan 2015 15:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%AD%A66-%E4%B8%80%E4%B8%AA%E6%A0%B7%E6%9C%AC%E7%9A%84%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD/</guid><description>好了，别人给你一个置信区间，置信水平，我们是否相信它呢？没办法，有时候只有自己印证才能相信！！！ 所以，我们只有提取一个样本，检验别人提供给我们的信息是否做假。 基本概念 检验统计量 就是你怀疑的那个参数，例如总体均值，总体方差等 零假设($H_0$)： 一般指那个参数成立或更好，如$\ma</description></item><item><title>数理统计学5-一个样本的区间估计</title><link>https://mlyixi.github.io/post/math/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%AD%A65-%E4%B8%80%E4%B8%AA%E6%A0%B7%E6%9C%AC%E7%9A%84%E5%8C%BA%E9%97%B4%E4%BC%B0%E8%AE%A1/</link><pubDate>Thu, 29 Jan 2015 14:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%AD%A65-%E4%B8%80%E4%B8%AA%E6%A0%B7%E6%9C%AC%E7%9A%84%E5%8C%BA%E9%97%B4%E4%BC%B0%E8%AE%A1/</guid><description>Jan 29, 2015 点估计在实际中其实没什么用，因为样本与总体分布之间总有偏差，我们用一个最可能的值来估计其实是不准确的。 通常我们都可以容忍一定的偏差，但是你得给我一个可信度，于是，区间估计就应运而生了。 概念 置信水平$1-p$ 指总体参数落到置信区间中的概率。 置信区间$[\hat{\theta_</description></item><item><title>数理统计学4-一个样本的点估计</title><link>https://mlyixi.github.io/post/math/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%AD%A64-%E4%B8%80%E4%B8%AA%E6%A0%B7%E6%9C%AC%E7%9A%84%E7%82%B9%E4%BC%B0%E8%AE%A1/</link><pubDate>Thu, 29 Jan 2015 13:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%AD%A64-%E4%B8%80%E4%B8%AA%E6%A0%B7%E6%9C%AC%E7%9A%84%E7%82%B9%E4%BC%B0%E8%AE%A1/</guid><description>通俗的讲，点估计就是用样本值的一个函数去估计总体分布的参数。 数学表述 已知总体分布形式为$D(\theta,&amp;hellip;)$，其参数未知，抽样得一个样本${x_i}$，我们想估计总体分布各参数的一个函数值$a=f(\theta,&amp;hellip;)$, 通过$\hat{a}=g(x</description></item><item><title>数理统计学3-正态分布的导出分布</title><link>https://mlyixi.github.io/post/math/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%AD%A63-%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%E7%9A%84%E5%AF%BC%E5%87%BA%E5%88%86%E5%B8%83/</link><pubDate>Thu, 29 Jan 2015 12:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%AD%A63-%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%E7%9A%84%E5%AF%BC%E5%87%BA%E5%88%86%E5%B8%83/</guid><description>由于我们现实中随机变量一般都服从正态分布，所以，正态分布的随机变量的函数分布在统计学中应用广泛。 $\chi^2$分布 又叫卡方分布。 定理：如果$X\sim N(0,1)$，$Z=X^2\sim \chi_1^2$ 定理：如果$Z_i\sim \chi_1^2$，则$U=\sum_i Z_i\sim \chi_n^2$ t分布 定理：如果$X</description></item><item><title>数理统计学2-基本概念</title><link>https://mlyixi.github.io/post/math/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%AD%A62-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</link><pubDate>Thu, 29 Jan 2015 11:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%AD%A62-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</guid><description>其实数理统计的基本概念应该建立在平稳随机过程的基础上,只不过由于统计学的重要性,我们在没有学习随机过程前就要学习统计学,所以,没办法. 平稳过程解释 假设有一个物理量是平稳过程$X(t,\zeta)$,服从某一分布$D(\theta,&amp;hellip;)$. 平稳过程随时间空间不变,所以</description></item><item><title>数理统计学1-导论</title><link>https://mlyixi.github.io/post/math/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%AD%A61-%E5%AF%BC%E8%AE%BA/</link><pubDate>Thu, 29 Jan 2015 10:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%AD%A61-%E5%AF%BC%E8%AE%BA/</guid><description>作为概率论的应用,统计学有不可估量的重要性.所以还是把我理解的统计学放上来. 首先,让我们把视线从数学的抽象转移到现实的具体吧. 误差 概率论只存在于数学概念中,如何将其结论应用于现实世界中呢? 随机误差 如果我们认为某一个物理量(变量)是概率分布已知的随机变量,当我们观察它的时候,它就会</description></item><item><title>随机过程4-连续性和微分</title><link>https://mlyixi.github.io/post/math/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B4-%E8%BF%9E%E7%BB%AD%E6%80%A7%E5%92%8C%E5%BE%AE%E5%88%86/</link><pubDate>Fri, 24 Oct 2014 14:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B4-%E8%BF%9E%E7%BB%AD%E6%80%A7%E5%92%8C%E5%BE%AE%E5%88%86/</guid><description>我们知道,随机过程$X(t)$是一族$X(t,\zeta_i)$的函数. 我们如何讨论它的连续性呢? 连续性 很明显地,我们可以说如果这族中每个成员在t处连续,我们就说随机过程对每个实验结果在$t$处连续. 但是这个定义太强太限制了. 于是我们想到了随机变量的收敛性. 比如可以定义依概率连续</description></item><item><title>随机过程3-一个随机过程的函数</title><link>https://mlyixi.github.io/post/math/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B3-%E4%B8%80%E4%B8%AA%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E7%9A%84%E5%87%BD%E6%95%B0/</link><pubDate>Thu, 23 Oct 2014 18:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B3-%E4%B8%80%E4%B8%AA%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E7%9A%84%E5%87%BD%E6%95%B0/</guid><description>随机过程经常用于信号处理,所以一般都是从系统角度进行论述的.而一个随机过程的函数其实是不准确的,但是我们要比对随机变量,所以还是这样命名. 给定一个随机过程$X(t)$作为输入,经过系统,输出为随机过程$Y(t)$,记为: $$ Y(t)=T[X(t)] $$ 这里算子$T$可理解为一种复杂的函数. 确定性 如果$X(</description></item><item><title>随机过程2-平稳性</title><link>https://mlyixi.github.io/post/math/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B2-%E5%B9%B3%E7%A8%B3%E6%80%A7/</link><pubDate>Thu, 23 Oct 2014 16:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B2-%E5%B9%B3%E7%A8%B3%E6%80%A7/</guid><description>狭义平稳性 定义 如果时间起点的推移不影响它的统计性质,则我们说随机过程$X(t)$是(狭义)平稳的. 联合平稳 有限阶平稳 广义平稳性 定义 如果随机变量的期望是常量而自相关只依赖于 $$ t_1-t_2 $$ 联合平稳 渐近平稳 周期平稳 平稳增量</description></item><item><title>随机过程1-基本概念</title><link>https://mlyixi.github.io/post/math/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</link><pubDate>Thu, 23 Oct 2014 14:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</guid><description>在上面几节中我们讨论了概率论,定义了随机变量,同时了解了最常用的重复试验其实是定义了一个随机变量序列,并讨论了大数定理和中心极限定理的意义. 重复试验是如此的重要,我们能不能扩充一下随机变量,使它天然地具备这个性质,并且适用于更广的情况,比如实验结果是随时间改变的? 自然而然的,我们</description></item><item><title>概率论12-参数估计</title><link>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA12-%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/</link><pubDate>Wed, 22 Oct 2014 14:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA12-%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/</guid><description>在统计学中我们有时候不能知道总体的全部信息而只能知道部分样本信息(这里不讨论大数据= =.). 我们要做的是,根据样本信息来推测总体信息. 这在统计学中有一个术语叫:统计推断,而它又分为两类,即参数估计(估计理论)和假设检验(检测理论). 现在我们先不考虑统计学中的参数估计问题,让我们先来看看</description></item><item><title>概率论11-中心极限定理</title><link>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA11-%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/</link><pubDate>Wed, 22 Oct 2014 12:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA11-%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/</guid><description>上一节介绍的大数定理指出,对于随机实验$\overline{\mathfrak{E}}$,其密度函数PDF总是集中在它的平均值附近.但是这个密度的实际形状确没有讨论.那么,这个形状或PDF函数形式是怎么样的呢?这就是中心极限定理讨论的. 中心极限定理 连续型 随机变量$X_i$是连续且</description></item><item><title>概率论10-收敛及大数定理</title><link>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA10-%E6%94%B6%E6%95%9B%E5%8F%8A%E5%A4%A7%E6%95%B0%E5%AE%9A%E7%90%86/</link><pubDate>Wed, 22 Oct 2014 10:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA10-%E6%94%B6%E6%95%9B%E5%8F%8A%E5%A4%A7%E6%95%B0%E5%AE%9A%E7%90%86/</guid><description>接下来,我们终于摆脱各种恼人的公式推导,可以换一个新的视角重新审视概率论了:以概率论和统计学相结合的角度再来看看概率论. 首先,我们接着上节内容看看,随机变量序列有没有极限. 随机变量序列的极限的定义 我们知道数列$x_n$的极限定义为: 若对给定的$\delta \gt 0$,我们总能找到一整</description></item><item><title>概率论9-随机变量序列/向量</title><link>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA9-%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%BA%8F%E5%88%97-%E5%90%91%E9%87%8F/</link><pubDate>Mon, 20 Oct 2014 10:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA9-%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%BA%8F%E5%88%97-%E5%90%91%E9%87%8F/</guid><description>在概率论7/8中我们介绍了两个随机变量的情况,这里我假设读者有自行推导更多随机变量(随机向量,随机序列)的能力,就随机向量这块就简单说明下. 联合分布 $$ F(x_1,\cdots,x_n)=P\lbrace X_1 \le x_1,\cdots, X_n\le x_n\rbrace $$ 密度函数 $$ f(x_1,\cdots,x_n) $$ 边缘分布 $$ F(x_1,x_3)=F(x_1,\infty,x_3,\infty) $$ 随机变量的函数 由$f(x_1,\cdots,x_n)$及已知函数$g_i(x_1,\cd</description></item><item><title>概率论8-两个随机变量的函数</title><link>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA8-%E4%B8%A4%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%87%BD%E6%95%B0/</link><pubDate>Mon, 13 Oct 2014 16:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA8-%E4%B8%A4%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%87%BD%E6%95%B0/</guid><description>一个函数 假定我们现在有一个函数$z=g(x,y)$,我们用随机变量$X$和$Y$代入得到的新随机变量$Z=g(X,Y)$服从什么分布呢? 由上一章我们知道,对于二维随机变量的联合分布函数是其密度函数的二维平面积分,从这里出发,我们可以得到多维随机变量函数的分布函数 分布函数 假设$X$</description></item><item><title>概率论7-两个随机变量</title><link>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA7-%E4%B8%A4%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F/</link><pubDate>Mon, 13 Oct 2014 14:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA7-%E4%B8%A4%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F/</guid><description>之前我们介绍了一个随机变量的情形,现在我们把它推广到两个或多个随机变量. 联合分布 如果我们有两个随机变量$X,Y$,则集合$\lbrace X \le x\rbrace$和$\lbrace Y \le y\rbrace$都是事件,分别有概率$P\lbrace X \le x\rbrace=F_X(x) P\lbrace Y \le y\rbrace=F_Y(y)$ 在笛卡尔乘积空间,我们定义一个</description></item><item><title>概率论6-一个随机变量的函数</title><link>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA6-%E4%B8%80%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%87%BD%E6%95%B0/</link><pubDate>Mon, 13 Oct 2014 12:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA6-%E4%B8%80%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%87%BD%E6%95%B0/</guid><description>我们已知一个函数$y=g(x)$,然后用随机变量$X$代替$x$生成的$Y$是一个新的随机变量. 分布函数 $$F_Y(y)=P\lbrace Y \le y \rbrace=P\lbrace X \in I_y \rbrace$$ 其中$I_y$表示使$g(x)\le y$成立的所有实数$x$的集合 密度函数 定理: 对一给定的$y$,为求$f_Y(y)$,我们先求解关于$x$的方程$y=g(x</description></item><item><title>概率论5-一个随机变量</title><link>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA5-%E4%B8%80%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F/</link><pubDate>Mon, 13 Oct 2014 10:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA5-%E4%B8%80%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F/</guid><description>下面的5-9节内容基本上就是课本上罗列的最多的公式了,比较 枯燥. 我只提供大致的一个框架,有必要才做一些解释. 前文介绍了随机变量的概念,它其实是对结果(元事件)的量化.一般而言,我们用大写字母表示随机变量,并且如果我们要谈到好几个随机变量,我们总是假定它们是定义在同一个实验上的. 随</description></item><item><title>概率论4-独立事件</title><link>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA4-%E7%8B%AC%E7%AB%8B%E4%BA%8B%E4%BB%B6/</link><pubDate>Sun, 12 Oct 2014 10:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA4-%E7%8B%AC%E7%AB%8B%E4%BA%8B%E4%BB%B6/</guid><description>在前一章,我们提到了独立事件,并指出了什么是独立事件,但是还是有些模糊的.独立事件之于概率论,是有其特殊意义的.书上说,由于独立性概念才使得概率论没有仅被当作测试论的一个分支,而发展成一门与之分离的学科. 我们可以看出,独立的概念有独立于概率论的一面. 那么,为什么会有独立事件? 概率</description></item><item><title>概率论3-条件概率</title><link>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA3-%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87/</link><pubDate>Thu, 09 Oct 2014 10:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA3-%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87/</guid><description>这一节我们讨论条件的概念 问题 我们都清楚,已知一个具有非零概率的事件$\mathscr M$,在$\mathscr M$下事件$\mathscr A$发生的概率为: $$P(\mathscr A|\mathscr M)=\frac{P(\mathscr A \mathscr M)}{P(\mathscr M)}$$ 如果我们解释成$\mathscr A$在条件$\mathscr M$下的概率等于它们同时发生的概率除以条件$\ma</description></item><item><title>概率论2-基本概念</title><link>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA2-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</link><pubDate>Tue, 07 Oct 2014 10:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA2-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</guid><description>下面我们指出概率论的公理化定义 试验 首先,我们必须明确概率论中的两个抽象概念:结果和事件. 一次试验指的是一次已经明确规定的实验.我们可以观察到单个的结果$\zeta_i$,而如果事件$\mathscr A$在逻辑上包含了某个结果, 我们就称该事件在这次试验中出现. 我们对只包含一个结果的</description></item><item><title>概率论1-什么是概率论</title><link>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA1-%E4%BB%80%E4%B9%88%E6%98%AF%E6%A6%82%E7%8E%87%E8%AE%BA/</link><pubDate>Mon, 06 Oct 2014 10:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA1-%E4%BB%80%E4%B9%88%E6%98%AF%E6%A6%82%E7%8E%87%E8%AE%BA/</guid><description>前言 发现一本概率论与随机过程的好书《概率、随机变量与随机过程》，把笔记记录成博客。 我们首先要问，什么是概率论，为什么会有概率论？ 我们对物理世界和其抽象模型的区别是容易接受的，比如物理学. 同时我们会认为：宇宙是按确定性规律发展的，一些规律精确地规定了宇宙的未来，只是由于我们的无和或</description></item><item><title>Probability Theory: the logic of science</title><link>https://mlyixi.github.io/post/math/Probability-Theory-the-logic-of-science/</link><pubDate>Wed, 03 Sep 2014 10:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/Probability-Theory-the-logic-of-science/</guid><description>Plausible reasoning The actual science of logic is conversant at present only with things either certain, impossible, or entirely doubtful, none of which (fortunately) we have to reason on. Therefore the true logic for this world is the calculus of Probabilities, which takes account of the magnitude of the probability which is, or ought to be, in a reasonable man's mind. &amp;ndash;Maxwell Aristotle deductive reasoning(apodeixis) strong syllogism if A is true, then B is true; now A is true, therefore B is true if A is true, then B is true; now B is false, therefore A is false Plausible reasoning weak syllogism(epagoge) if A is true, then B is true; now B is true, therefore A becomes more plausible. if A is true, then B is true, now A is false, therefore B becomes less plausible. weaker syllogism if</description></item><item><title>概率分布总结</title><link>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%E6%80%BB%E7%BB%93/</link><pubDate>Wed, 03 Sep 2014 10:08:52 +0800</pubDate><guid>https://mlyixi.github.io/post/math/%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%E6%80%BB%E7%BB%93/</guid><description>常见分布 均匀分布: $rand(M,N)$ 伯努利分布(01分布,两点分布): $x=rand(M,N); y=(sign(x-P+eps)+1)/2, P为1的概率$ 二项分布:N个独立的伯努利分布中1的次数,$binornd(N,P,m)$ 泊松分布:描述单位时间内随机事件发生次数的概率分布,$poissrnd()$ 正态分布(高斯分布):$normrnd()$ 标准正态分布:</description></item></channel></rss>